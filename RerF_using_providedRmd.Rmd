---
title: "Random Forest Experiments Using Trunk and Parity Datasets"
author: "James Browne"
date: "November 22, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, error=FALSE, message=FALSE, cache = FALSE)
library(randomForest)
```
* Each subexperiment is run according to the parameters specified.
* non-xgboost sub-experiments are run 25 times.  xgboost sub-experiments is run 3 times.
* after each run a test set is run through the model and an error is determined.  The error statistics are provided for each sub-experiment.

**********************************************************************************
#### Experiment 1-  Run 25 rounds.  Each round: Train using Trunk_XTrain.
**********************************************************************************
```{r exp1_setup, cache = FALSE}
ptm_total <- proc.time()
trunkX<- read.csv("~/gitRepos/old.RandomForest/Trunk/Trunk_Xtrain.dat", header=FALSE)
trunkY<- read.csv("~/gitRepos/old.RandomForest/Trunk/Trunk_Ytrain.dat", header=FALSE)
trunkY<- factor(data.matrix(trunkY))
testX<- read.csv("~/gitRepos/old.RandomForest/Trunk/Trunk_Xtest.dat", header=FALSE)
testY<- read.csv("~/gitRepos/old.RandomForest/Trunk/Trunk_Ytest.dat", header=FALSE)
testY<- factor(data.matrix(testY))
library(randomForest)
rounds <- 25
```
===============================================================================

##### Classifier- RF
* mtry = mdim^.5
* 1000 trees
  
```{r C_RF_trunk}
set.seed(71)
results = vector()
ptm <- proc.time()
for (i in 1:rounds){
trunk.rf <- randomForest(trunkX, trunkY, testX, testY, ntree= 1000)
results[i] <- trunk.rf$test$err.rate[trunk.rf$ntree]*100
}
ptm<- proc.time() - ptm
cat(paste("average time per iteration- ", ptm[3]/rounds, " seconds"))
summary(results)

```
===============================================================================

##### Classifier- RF
* mtry = mdim^.5
* 500 trees
  
```{r C_RF_trunk_s}
set.seed(71)
results = vector()
ptm <- proc.time()
for (i in 1:rounds){
trunk.rf <- randomForest(trunkX, trunkY, testX, testY, ntree= 500)
results[i] <- trunk.rf$test$err.rate[trunk.rf$ntree]*100
}
ptm<- proc.time() - ptm
cat(paste("average time per iteration- ", ptm[3]/rounds, " seconds"))
summary(results)

```
===============================================================================
  
##### Classifier- RerF
* A is mdim by mdim
* A is identity matrix.
* 1000 trees
* mtry = mdim^.5
```{r C_RerF_20_trunk}
set.seed(71)
results = vector()
ptm <- proc.time()
for (i in 1:rounds){
trunk.rf <- randomForest(trunkX, trunkY, testX, testY, ntree=1000,RerF=20)
results[i] <- trunk.rf$test$err.rate[trunk.rf$ntree]*100
}
ptm<- proc.time() - ptm
cat(paste("average time per iteration- ", ptm[3]/rounds, " seconds"))
summary(results)
```
===============================================================================
     
##### Classifier- RerF
* A is mdim by mdim
* A is identity matrix.
* 500 trees
* mtry = mdim^.5
```{r C_RerF_20_trunk_s}
set.seed(71)
results = vector()
ptm <- proc.time()
for (i in 1:rounds){
trunk.rf <- randomForest(trunkX, trunkY, testX, testY, ntree=500,RerF=20)
results[i] <- trunk.rf$test$err.rate[trunk.rf$ntree]*100
}
ptm<- proc.time() - ptm
cat(paste("average time per iteration- ", ptm[3]/rounds, " seconds"))
summary(results)
```
===============================================================================

##### Classifier- RerF
* A is mdim by mdim
* Sparse A: mdim non zero entries all of which have 50/50 chance of being 1/-1.
* 1000 trees
* mtry = mdim^.5
```{r C_RerF_6_trunk}
set.seed(71)
results = vector()
ptm <- proc.time()
for (i in 1:rounds){
trunk.rf <- randomForest(trunkX, trunkY, testX, testY, ntree=1000, RerF=6)
results[i] <- trunk.rf$test$err.rate[trunk.rf$ntree]*100
}
ptm<- proc.time() - ptm
cat(paste("average time per iteration- ", ptm[3]/rounds, " seconds"))
summary(results)
```
===============================================================================
  
##### Classifier- RerF
* A is mdim by mdim
* Sparse A: mdim non zero entries all of which have 50/50 chance of being 1/-1.
* 500 trees
* mtry = mdim^.5
```{r C_RerF_6_trunk_s}
set.seed(71)
results = vector()
ptm <- proc.time()
for (i in 1:rounds){
trunk.rf <- randomForest(trunkX, trunkY, testX, testY, ntree=500, RerF=6)
results[i] <- trunk.rf$test$err.rate[trunk.rf$ntree]*100
}
ptm<- proc.time() - ptm
cat(paste("average time per iteration- ", ptm[3]/rounds, " seconds"))
summary(results)
```
===============================================================================
  
##### Classifier- RerF
* A is mdim by mtry
* Sparse A: mdim non zero entries all of which have 50/50 chance of being 1/-1.
* 1000 trees
* mtry = mdim^.5
```{r C_RerF_7_trunk}
set.seed(71)
results = vector()
ptm <- proc.time()
for (i in 1:rounds){
trunk.rf <- randomForest(trunkX, trunkY, testX, testY, ntree=1000, RerF=7)
results[i] <- trunk.rf$test$err.rate[trunk.rf$ntree]*100
}
ptm<- proc.time() - ptm
cat(paste("average time per iteration- ", ptm[3]/rounds, " seconds"))
summary(results)
```
===============================================================================
    
##### Classifier- RerF
* A is mdim by mtry
* Sparse A: mdim non zero entries all of which have 50/50 chance of being 1/-1.
* 500 trees
* mtry = mdim^.5
```{r C_RerF_7_trunk_s}
set.seed(71)
results = vector()
ptm <- proc.time()
for (i in 1:rounds){
trunk.rf <- randomForest(trunkX, trunkY, testX, testY, ntree=500, RerF=7)
results[i] <- trunk.rf$test$err.rate[trunk.rf$ntree]*100
}
ptm<- proc.time() - ptm
cat(paste("average time per iteration- ", ptm[3]/rounds, " seconds"))
summary(results)
```
===============================================================================

##### Classifier- XGBoost
* num_rounds = 1
* 500 trees
```{r C_XGBoost_1_trunk}
library(xgboost)
set.seed(71)
results = vector()
ptm <- proc.time()
for (i in 1:3){
bst = xgboost(data = as.matrix(trunkX), label = trunkY, max.depth = 4, num_parallel_tree = 500, subsample = .5, colsample_bytree = 0.5, nround = 1, objective = "multi:softmax", num_class = 3)
testYB<- as.numeric(unlist(read.csv("~/gitRepos/old.RandomForest/Trunk/Trunk_Ytest.dat", header=FALSE)))
test = predict(bst, as.matrix(testX))
tot_wrong = 0
testYB <- testYB + 1
for (m in 1:length(testYB)){
  if (testYB[m] != test[m]){
    tot_wrong = tot_wrong + 1
  }
}
results[i] <- tot_wrong/length(testYB)*100
}
ptm<- proc.time() - ptm
cat(paste("average time per iteration- ", ptm[3]/rounds, " seconds"))
summary(results)
```
=================================================================================

##### Classifier- XGBoost
* num_rounds = 6
* 500 trees
```{r C_XGBoost_6_trunk}
library(xgboost)
set.seed(71)
results = vector()
ptm <- proc.time()
for (i in 1:3){
bst = xgboost(data = as.matrix(trunkX), label = trunkY, max.depth = 4, num_parallel_tree = 500, colsample_bytree = 0.5, nround = 6, objective = "multi:softmax", num_class = 3)
testYB<- as.numeric(unlist(read.csv("~/gitRepos/old.RandomForest/Trunk/Trunk_Ytest.dat", header=FALSE)))
test = predict(bst, as.matrix(testX))
tot_wrong = 0
testYB <- testYB + 1
for (m in 1:length(testYB)){
  if (testYB[m] != test[m]){
    tot_wrong = tot_wrong + 1
  }
}
results[i] <- tot_wrong/length(testYB)*100
}
ptm<- proc.time() - ptm
cat(paste("average time per iteration- ", ptm[3]/rounds, " seconds"))
summary(results)
```
===============================================================================


**********************************************************************************
#### Experiment 2-  Run 25 rounds.  Each round: Train using Parity_Xtrain.
**********************************************************************************
```{r exp2_setup, cache = FALSE}
parityX<- read.csv("~/gitRepos/old.RandomForest/Parity/Parity_Xtrain.dat", header=FALSE)
parityY<- read.csv("~/gitRepos/old.RandomForest/Parity/Parity_Ytrain.dat", header=FALSE)
parityY<- factor(data.matrix(parityY))
testX<- read.csv("~/gitRepos/old.RandomForest/Parity/Parity_Xtest.dat", header=FALSE)
testY<- read.csv("~/gitRepos/old.RandomForest/Parity/Parity_Ytest.dat", header=FALSE)
testY<- factor(data.matrix(testY))
library(randomForest)
```
===============================================================================

##### Classifier- RF
* mtry = mdim^.5
* 1000 trees
```{r C_RF_parity}
set.seed(71)
results = vector()
ptm <- proc.time()
for (i in 1:rounds){
parity.rf <- randomForest(parityX, parityY, testX, testY, ntree=1000)
results[i] <- parity.rf$err.rate[parity.rf$ntree]*100
}
ptm<- proc.time() - ptm
cat(paste("average time per iteration- ", ptm[3]/rounds, " seconds"))
summary(results)
```
===============================================================================

##### Classifier- RerF
* A is mdim by mdim
* Sparse A: mdim non zero entries all of which have 50/50 chance of being 1/-1.
* 1000 trees
* mtry = mdim^.5
```{r C_RerF_6_parity}
set.seed(71)
results = vector()
ptm <- proc.time()
for (i in 1:rounds){
parity.rf <- randomForest(parityX, parityY, testX, testY, ntree=1000, RerF=6)
results[i] <- parity.rf$err.rate[parity.rf$ntree]*100
}
ptm<- proc.time() - ptm
cat(paste("average time per iteration- ", ptm[3]/rounds, " seconds"))
summary(results)
```
===============================================================================

##### Classifier- RerF
* A is mdim by mtry
* Sparse A: mdim non zero entries all of which have 50/50 chance of being 1/-1.
* 1000 trees
* mtry = mdim^.5
```{r C_RerF_7_parity}
set.seed(71)

results = vector()
ptm <- proc.time()
for (i in 1:rounds){
parity.rf <- randomForest(parityX, parityY, testX, testY, ntree=1000, RerF=7)
results[i] <- parity.rf$err.rate[parity.rf$ntree]*100
}
ptm<- proc.time() - ptm
cat(paste("average time per iteration- ", ptm[3]/rounds, " seconds"))
summary(results)
ptm_total<- proc.time() - ptm
cat(paste("total time- ", ptm_total[3], " seconds"))
```
===============================================================================

##### Classifier- XGBoost
* num_rounds = 1
* 500 trees
```{r C_XGBoost_1_par}
library(xgboost)
set.seed(71)
results = vector()
ptm <- proc.time()
for (i in 1:3){
bst = xgboost(data = as.matrix(parityX), label = parityY, max.depth = 4, num_parallel_tree = 500, subsample = .5, colsample_bytree = 0.5, nround = 1, objective = "multi:softmax", num_class = 3)
testYB<- as.numeric(unlist(read.csv("~/gitRepos/old.RandomForest/Parity/Parity_Ytest.dat", header=FALSE)))
test = predict(bst, as.matrix(testX))
tot_wrong = 0
testYB <- testYB + 1
for (m in 1:length(testYB)){
  if (testYB[m] != test[m]){
    tot_wrong = tot_wrong + 1
  }
}
results[i] <- tot_wrong/length(testYB)*100
}
ptm<- proc.time() - ptm
cat(paste("average time per iteration- ", ptm[3]/rounds, " seconds"))
summary(results)
```
=================================================================================

##### Classifier- XGBoost
* num_rounds = 6
* 500 trees
```{r C_XGBoost_6_par}
library(xgboost)
set.seed(71)
results = vector()
ptm <- proc.time()
for (i in 1:3){
bst = xgboost(data = as.matrix(trunkX), label = trunkY, max.depth = 4, num_parallel_tree = 500, colsample_bytree = 0.5, nround = 6, objective = "multi:softmax", num_class = 3)
testYB<- as.numeric(unlist(read.csv("~/gitRepos/old.RandomForest/Parity/Parity_Ytest.dat", header=FALSE)))
test = predict(bst, as.matrix(testX))
tot_wrong = 0
testYB <- testYB + 1
for (m in 1:length(testYB)){
  if (testYB[m] != test[m]){
    tot_wrong = tot_wrong + 1
  }
}
results[i] <- tot_wrong/length(testYB)*100
}
ptm<- proc.time() - ptm
cat(paste("average time per iteration- ", ptm[3]/rounds, " seconds"))
summary(results)
```
===============================================================================